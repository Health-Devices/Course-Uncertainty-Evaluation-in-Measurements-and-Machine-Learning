{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELG_7172B_Lecture7_Uncertainty Propagation\n",
    "\n",
    "## objectives\n",
    "\n",
    "+ Introduction to uncertainty propagation\n",
    "+ Perturbation method \n",
    "+ Monte Carlo method\n",
    "+ GUM\n",
    "+ Examples\n",
    "\n",
    "## List of symbols:\n",
    "\n",
    "+ $U$ - expanded uncertainty\n",
    "+ $u$ - standard uncertainty\n",
    "+ $\\sigma$ - standard deviation\n",
    "+ $\\sum$ - the sum of variables\n",
    "+ $X$ - random variable\n",
    "+ $E[X]$ - the mean of random variable X\n",
    "+ $Var[X]$ - the variance of random variable X\n",
    "+ $S$ - standard uncertainty\n",
    "+ $C$ - covariance\n",
    "\n",
    "## Introduction to uncertainty propagation\n",
    "\n",
    "In statistics, propagation of uncertainty (or propagation of error) is the effect of variables' uncertainties (or errors, more specifically random errors) on the uncertainty of a function based on them. When the variables are the values of experimental measurements they have uncertainties due to measurement limitations (e.g., instrument precision) which propagate to the combination of variables in the function.\n",
    "\n",
    "The uncertainty u can be expressed in a number of ways. It may be defined by the absolute error Δx. Uncertainties can also be defined by the relative error (Δx)/x, which is usually written as a percentage. Most commonly, the uncertainty on a quantity is quantified in terms of the standard deviation, σ, the positive square root of variance, $σ^2$. The value of a quantity and its error are then expressed as an interval x ± u. If the statistical probability distribution of the variable is known or can be assumed, it is possible to derive confidence limits to describe the region within which the true value of the variable may be found. For example, the 68% confidence limits for a one-dimensional variable belonging to a normal distribution are approximately ± one standard deviation σ from the central value x, which means that the region x ± σ will cover the true value in roughly 68% of cases.\n",
    "\n",
    "If the uncertainties are correlated then covariance must be taken into account. Correlation can arise from two different sources. First, the measurement errors may be correlated. Second, when the underlying values are correlated across a population, the uncertainties in the group averages will be correlated.\n",
    "\n",
    "## Perturbation method\n",
    "\n",
    "The perturbation method is a method for computing the mean and standard deviation of a response quantity, which is based on the Taylor series expansion of the model response around the mean value of the input parameters.\n",
    "\n",
    "The progress of deriving the formulas is shown as follows:\n",
    "\n",
    "The Taylor series expansion of the model $M(x)$ around $x_0$:\n",
    "\n",
    "$$M(x) = M(x_0) + \\sum^M_{i=1}\\frac{\\partial M}{\\partial x_i}|_{x=x_0} (x_i-x_0) + \\frac{1}{2} \\sum^M_{i=1}\\sum^M_{j=1} \\frac{\\partial^2M}{\\partial x_i \\partial x_j}|_{x=x_0}(x_i-x_0)(x_j-x_0) + o(||x-x_0||^2) $$\n",
    "\n",
    "Let us replace x0 with $E[x]$ and get $E[M(x)]$:\n",
    "\n",
    "$$E[Y]= E[M(X)]\\approx M(u_x) + \\sum^M_{i=1}\\frac{\\partial M}{\\partial x_i}|_{x=x_i} E[(X_i-u_{x_i})] + \\frac{1}{2} \\sum^M_{i=1}\\sum^M_{j=1} \\frac{\\partial^2M}{\\partial x_i \\partial x_j}|_{x=u_x} E[(X_i-u_{x_i})(X_j-u_{x_j})] $$\n",
    "\n",
    "We know that $E[(x-u_x)]=0$ and $E[(x_i-u_{x_i})(x_j-u_{x_j})]=C_{ij}$ is the covariance of $x_i$ and $x_j$, so:\n",
    "\n",
    "$$E[Y]\\approx M(u_x) + \\frac{1}{2} \\sum^M_{i=1}\\sum^M_{j=1} C_{ij}\\frac{\\partial^2M}{\\partial x_i \\partial x_j}|_{x=u_x}$$\n",
    "\n",
    "If $C_{ij} = 0$, we can get that :\n",
    "\n",
    "$$E[Y]\\approx M(u_x) + \\frac{1}{2} \\sum^M_{i=1}\\frac{\\partial^2M}{\\partial x_i^2}|_{x=u_x} \\sigma ^2_{X_i}$$\n",
    "\n",
    "The variance of the response is computed as follows:\n",
    "\n",
    "$$Var[Y] = E[(Y-E[Y]^2)] \\approx E[(Y-M(u_x))^2]$$\n",
    "\n",
    "So we can get that :\n",
    "\n",
    "$$Var[Y] \\approx \\sum^M_{i=1}\\sum^M_{j=1} C_{ij} \\frac{\\partial M}{\\partial x_i }|_{x=u_x} \\frac{\\partial M}{\\partial x_j }|_{x=u_x} $$\n",
    "\n",
    "If $C_{ij} = 0$, we can get that :\n",
    "\n",
    "$$Var[Y] \\approx \\sum^M_{i=1}( \\frac{\\partial M}{\\partial x_i }|_{x=u_x})^2 \\sigma ^2_{X_i}$$\n",
    "\n",
    "## Monte Carlo method\n",
    "\n",
    "Monte Carlo methods (or Monte Carlo experiments) are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. Their essential idea is using randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three distinct problem classes:optimization, numerical integration, and generating draws from a probability distribution.\n",
    "\n",
    "In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the sample mean) of independent samples of the variable. When the probability distribution of the variable is parametrized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the stationary distribution is approximated by the empirical measures of the random states of the MCMC sampler.\n",
    "\n",
    "Here, Monte Carlo method is used as a method used for computing the mean and standard deviation of a response quantity, which is based on sampling from the original distribution. Assume that we get a sample set of x, then we can get:\n",
    "\n",
    "$$\\hat{u}_Y = \\frac {1}{n} \\sum^n_{k=1} M(x^{(k)})$$\n",
    "\n",
    "$$\\hat{\\sigma}^2_Y = \\frac {1}{n-1} \\sum^n_{k=1} (M(x^{(k)}-\\hat{u}_Y))^2$$\n",
    "\n",
    "According to the central limit theorem, $U_y$ is asymptotically Gaussian.\n",
    "\n",
    "So, here is the (1-$\\alpha$) confidence interval on $U_y$ :\n",
    "\n",
    "$$\\hat{u}_Y - u_{\\alpha /2} \\hat{\\sigma}_Y /\\sqrt{n-1}\\leq or \\le u \\leq or \\le \\hat{u}_Y + u_{\\alpha /2} \\hat{\\sigma}_Y /\\sqrt{n-1} $$\n",
    "\n",
    "where $u_{\\alpha /2} = -\\Phi^{-1}(1-\\alpha)$.\n",
    "\n",
    "## Definitions related to GUM\n",
    "\n",
    "+ Confidence, Significance and Coverage Factor (k-factor): Uncertainty is often quoted at a certain level of  confidence. The k-factor can be thought of as a multiplier that gives probability to an uncertainty. Mathematically the coverage ( k-factor) is the number of standard deviations from the mean that include the percentage confidence. Coverage factors are most often based upon the normal distribution and later in this monograph we give a variety of k-factors and the probability they represent. For example, a k-factor of 2 represents 95% probability.  \n",
    "\n",
    "\n",
    "+ True Value and Uncertainty Interval: One way we can overcome the problem of never knowing the true value is to identify our best estimate of the true value, and quote an UNCERTAINTY INTERVAL, or range, in which we reasonably expect the true value to lie. We now face the dichotomy of uncertainty analysis: In order to accurately identify the uncertainty interval in which a true value lies, it is necessary to know the true value. However, if we know the true value there is no uncertainty, the uncertainty interval is zero—and there is no need to take measurements! The consequence is that all uncertainty intervals are only estimates and therefore we always quote them with an associated probability that the true value lies within the quoted range.\n",
    "\n",
    "\n",
    "+ Systematic and Random Uncertainties: If the systematic uncertainty is small compared with the random scatter, then the true value might lie within the random scatter, and the scale might sometimes measure the correct true value. Of course, you have no way of knowing if this is the case! The terms systematic and random are “old” terms and as stated in the GUM, ‘There is not always a simple correspondence between the classification into categories A or B and the previously used classification into “random” and “systematic” uncertainties. The term “systematic uncertainty” can be misleading and should be avoided.’ Despite this declaration, the GUM continues to use these terms, and even includes the outdated terms ‘bias’ and ‘precision’. Therefore, while recognizing the terms systematic and random are archaic, we will also continue to use them since they are descriptive of the types of uncertainty encountered in daily measurements.\n",
    "\n",
    "\n",
    "+ Type A and Type B Uncertainties:  Type A uncertainties are those that are evaluated by the statistical analysis of a series of observations, whereas Type B uncertainties are those evaluated by any other means. If an uncertainty is based on a statistical analysis, it is to be treated as a Type A uncertainty. Most random uncertainties are Type A uncertainties. They vary each time a measurement is made. The uncertainty can be reduced by averaging lots of measurements, but it can never be totally eliminated. Any uncertainty not based on a statistical analysis is to be treated as a Type B uncertainty. Most systematic uncertainties are Type B uncertainties.\n",
    "\n",
    "\n",
    "+ Calibration : A transducer, or device under test (DUT), is calibrated by comparing it against a standard with a smaller amount of uncertainty. Calibration is expensive and time consuming, and therefore it is common practice to use calibration services to calibrate and provide a calibration certificate for each transducer. A calibration certificate should include an uncertainty which combines all the elemental uncertainties associated with the transducer itself.\n",
    "\n",
    "\n",
    "+ Elemental Uncertainties: Elemental uncertainties are those associated with a transducer or the parameter being measured. \n",
    "\n",
    "\n",
    "+ Standard Uncertainty and Expanded Uncertainty: Standard uncertainties are given the symbol lower-case u. Expanded uncertainties are given the symbol upper-case U. We can think of the standard uncertainty as the lowest common denominator for all uncertainty calculations, irrespective of their source, type or statistical distribution. If we reduce all elemental uncertainties to their standard uncertainty, we can combine them to find the standard uncertainty of a measurement. Standard uncertainty does not have a probability associated with it. The expanded uncertainty is found by applying a probability to the standard uncertainty. The most common way is to multiply the standard uncertainty with a coverage factor.\n",
    "\n",
    "\n",
    "+ Error or Uncertainty: Uncertainties can never be known exactly. They must be estimated and quoted with a statistical degree of confidence. Errors are fixed and known, typically from a calibration. They can be taken into account, and thus do not actually affect the final measurement.\n",
    "\n",
    "\n",
    "+ Propagation of Uncertainty: The procedure for determining the uncertainty in a calculated quantity based on the individual uncertainties for each measurement is called “uncertainty propagation.”\n",
    "\n",
    "\n",
    "##  Procedure for measuring uncertainty and uncertainty propagation based on GUM\n",
    "\n",
    "+ Confidence and significance are related by: \n",
    "\n",
    "$$Confidence+Significance=100\\%$$\n",
    "\n",
    "+ Finding the Standard Uncertainty when an Uncertainty Is Quoted at a Certain Level of Confidence: \n",
    "\n",
    "$$Standard\\  Uncertainty, u = \\frac{(uncertainty)}{k}$$\n",
    "\n",
    "+ Finding the Standard Uncertainty when an Elemental Uncertainty Is Given as a Standard Deviation with No Information About the Sample Size:\n",
    "\n",
    "$$Standard\\  Uncertainty, u = (Given\\  standard\\  deviation)$$\n",
    "\n",
    "+ Finding the Standard Uncertainty when the Uncertainty Is Given as a Standard Deviation and the Sample Size Is also Given: \n",
    "\n",
    "$$Standard\\  Uncertainty, u = \\frac {t_{95\\%,dof} (Given\\  standard\\  deviation)}{2}$$\n",
    "\n",
    "+ Combining Several Standard Uncertainties to find the Standard Uncertainty for a Single Measured Quantity The method recommended in the GUM is to first categorize all the uncertainties as Type A or Type B. The Type A and Type B combined standard uncertainties are then calculated separately as follows:\n",
    "\n",
    "$$Type\\ A\\ combined\\ standard\\ uncertainty = u_A = \\{ \\sum_t u_{A,i}^2 \\}^{\\frac{1}{2}}$$\n",
    "\n",
    "$$Type\\ B\\ combined\\ standard\\ uncertainty = u_B = \\{ \\sum_t u_{B,i}^2 \\}^{\\frac{1}{2}}$$\n",
    "\n",
    "+ The combined standard uncertainty for the measurement is then determined as:\n",
    "\n",
    "$$Standard\\ uncertainty\\ of\\ the\\ measurement = u_m = \\{ u_A^2 + u_B^2\\}$$\n",
    "\n",
    "+ The expanded uncertainty of a measurement, Um, depends upon a chosen level of confidence, and is calculated as:\n",
    "\n",
    "$$Uncertainty\\ of\\ the\\ measurement = U_m = k\\ u_m$$\n",
    "\n",
    "\n",
    "\n",
    "Summary of the Steps to Determine the Uncertainty of Measurement: \n",
    "\n",
    "+ 1.Determine the standard uncertainty for each elemental uncertainty, u. \n",
    "\n",
    "+ 2.Separately for the Type A and Type B uncertainties combine the standard uncertainties with an RSS calculation to get the total Type A uA and Type B uB standard uncertainties.\n",
    "\n",
    "+ 3.Use an RSS calculation to combine the total Type A and Type B uncertainties to get the total standard uncertainty in a measurement. \n",
    "\n",
    "+ 4.Multiply the standard uncertainty in measurement by a k-factor to get the expanded (total) uncertainty of measurement U, for a prescribed level of confidence\n",
    "\n",
    "\n",
    "## Example 1  Radiation Heat Transfer\n",
    "\n",
    "The problem we investigate is radiation heat transfer. When a hot body is close to a cold body, heat energy will radiate from the hot body to the cold body. The radiation heat transfer $q(W/m^2)$between two bodies is given by:\n",
    "$$q = c(T^4_1 - T^4_2)$$\n",
    "\n",
    "The radiation heat transfer between the two bodies is a function of their absolute temperatures, $T_1$ and $T_2$, and a parameter, c. For a full analysis, the parameter c is dependent upon several other quantities, but for this uncertainty propagation example we will assume that it has been determined separately and independently.\n",
    "\n",
    "For a particular pair of bodies let us assume that we know $c=45.0×10^{–9}±0.2×10^{–9}W/m^2/K^4$, and prior knowledge tells us that the hot and cold temperatures will be about $T_1$= 700 K and $T_2$=300 K. In setting up a test you have a choice of two different thermocouples you could use to measure the temperatures. Complete with all purchase costs, installation costs and signal conditioning, “regular grade” thermocouples cost $ 125 each, and “best grade” thermocouples cost 200 each. According to the manufacturer, regular thermocouples can record a maximum temperature of 1300°C with an uncertainty ±0.15%, and best grade thermocouples can record a maximum temperature of 1700°C with an uncertainty of ±0.5°C. Get the mean and variance of q.\n",
    "\n",
    "Accroding to the description, we can get:\n",
    "$$U_c = 0.2×10^{–9}W/m^2/K^4$$\n",
    "$$U_{T-REGULER} = \\frac{0.15×1300}{100} = 1.95°C$$\n",
    "$$U_{T-BEST} = 0.5°C$$\n",
    "\n",
    "1.Solve the problem using Monte Carlo:(Supposing we choose \"best grade\" for $T_1$ and \"regular grade\" for \"$T_2$\" ):\n",
    "\n",
    "Codes are shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of q is 10439.751765 W/m2.\n",
      "The variance of q is 819.262799 W/m2.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#sample from three variables\n",
    "n = 10000\n",
    "C = np.random.normal(45*10**-9, 0.1*10**-9, n)\n",
    "T1 = np.random.normal(700, 0.5/2, n)#Assuming we use the best to test the high temperature\n",
    "T2 = np.random.normal(300, 1.95/2, n)#assuming we use the regular to test the low temperature\n",
    "\n",
    "q = C*(T1**4 - T2**4)\n",
    "\n",
    "#get the mean and the variance of q\n",
    "print('The mean of q is %f W/m2.' % (q.mean()))\n",
    "print('The variance of q is %f W/m2.' % (q.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Solve the problem using perturbation method:(Supposing we choose \"best grade\" for $T_1$ and \"regular grade\" for \"$T_2$\" ):\n",
    "\n",
    "We can get that:\n",
    "$$\\sigma_c = 0.1×10^{–9}W/m^2/K^4$$\n",
    "$$\\sigma_{T-REGULER} = \\frac{0.15×1300}{100×2} = 0.975°C$$\n",
    "$$\\sigma_{T-BEST} = 0.25°C$$\n",
    "\n",
    "According to the formula we discussed before ($C_{ij}$= 0), where $C_{ij}$ is the covariance of $x_i$ and $x_j$:\n",
    "\n",
    "$$E[Y]\\approx M(u_x) + \\frac{1}{2} \\sum^M_{i=1}\\frac{\\partial^2M}{\\partial x_i^2}|_{x=u_x} \\sigma ^2_{X_i}$$\n",
    "\n",
    "$$Var[Y] \\approx \\sum^M_{i=1}( \\frac{\\partial M}{\\partial x_i }|_{x=u_x})^2 \\sigma ^2_{X_i}$$\n",
    "\n",
    "So we can get the mean of q is $10440 W/m^2$ and the variance of q is $805 W/m^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2  Pulse Oximeter\n",
    "\n",
    "Arterial blood oxygen content is one of the most requested tests performed on critically ill patients. The arterial blood is of the same saturation throughout the arterial system. The result is expressed as a percentage ratio of oxygenated hemoglobin ($HbO_2$) to the total amount of hemoglobin ($Hb+HbO_2$). It is called the oxygen saturation $SaO_2$%.\n",
    "\n",
    "The pulse oximeter was used to indicate the final reading $SP0_2$% while the especially designed testing device was used to study changes in the raw values of the specific quantities: $U_o1, U_p1, U_o2, U_p2, Y_1, Y_2, Y$:\n",
    "\n",
    "$$F = SyO_2= \\frac{1.11-0.22\\frac{U_p1}{U_o1}\\frac{U_o2}{U_p2}}{1.00-0.05\\frac{U_p1}{U_o1}\\frac{U_o2}{U_p2}}$$\n",
    "\n",
    "According to the formula we discussed before:\n",
    "\n",
    "$$Var[Y] \\approx \\sum^M_{i=1}\\sum^M_{j=1} C_{ij} \\frac{\\partial M}{\\partial x_i }|_{x=u_x} \\frac{\\partial M}{\\partial x_j }|_{x=u_x} $$\n",
    "\n",
    "We can get:\n",
    "\n",
    "Var[F] = $W_1 +W_2 +W_3$ ,where $W_I$ and $W_2$ contain the variances and covariances, respectively.\n",
    "\n",
    "$$W_1 = (\\frac{\\partial F}{\\partial U_{o1}})^2 S_{U_{o1}} + (\\frac{\\partial F}{\\partial U_{p1}})^2 S_{U_{p1}}+ (\\frac{\\partial F}{\\partial U_{o2}})^2 S_{U_{02}} + (\\frac{\\partial F}{\\partial U_{p2}})^2 S_{U_{p2}}$$\n",
    "\n",
    "$$W_2 = 2(\\frac{\\partial F}{\\partial U_{o1}}\\frac{\\partial F}{\\partial U_{p1}} S_{U_{o1},U_{p1}} + \\frac{\\partial F}{\\partial U_{o1}}\\frac{\\partial F}{\\partial U_{o2}} S_{U_{o1},U_{o2}} + \\frac{\\partial F}{\\partial U_{o1}}\\frac{\\partial F}{\\partial U_{p2}} S_{U_{o1},U_{p2}} + \\frac{\\partial F}{\\partial U_{p1}}\\frac{\\partial F}{\\partial U_{o2}} S_{U_{p1},U_{o2}} +\\frac{\\partial F}{\\partial U_{p1}}\\frac{\\partial F}{\\partial U_{p2}} S_{U_{p1},U_{p2}} + \\frac{\\partial F}{\\partial U_{p2}}\\frac{\\partial F}{\\partial U_{o2}} S_{U_{p2},U_{o2}})$$\n",
    "\n",
    "So we can get the standard deviation of F: $S_F = \\sqrt {Var[F]}$ \n",
    "\n",
    "95% probability has been assumed to determine the confidence interval as equal to $\\pm$ expanded uncertainty equal to $\\pm$ 2 combined standard uncertainty. \n",
    "\n",
    "So the expanded uncertainty $U_F = 2S_F$\n",
    "\n",
    "From the paper, $W_1 = 1.1×10^{-4}$, $W_2 = -0.8×10^{-4}$\n",
    "\n",
    "So U_F = 1.1% \n",
    "\n",
    "The result of a measurement made by the testing device, given in the general formula: P(corrected result - expanded uncertainty $\\le$ the value of the measurand $\\le$ corrected result + expanded uncertainty)= $\\alpha$, may be finally written as P(93.4% $\\le$ unknown value of the measurand $SaPO_2$% $\\le$95.6%) = 0.95\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference \n",
    "\n",
    "[1] https://www.bipm.org/utils/common/documents/jcgm/JCGM_100_2008_E.pdf\n",
    "\n",
    "[2] http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4362565\n",
    "\n",
    "[3] https://www.ethz.ch/content/dam/ethz/special-interest/baug/ibk/risk-safety-and-uncertainty-dam/publications/reports/HDRSudret.pdf\n",
    "\n",
    "[4] https://en.wikipedia.org/wiki/Propagation_of_uncertainty\n",
    "\n",
    "[5] https://en.wikipedia.org/wiki/Monte_Carlo_method"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
