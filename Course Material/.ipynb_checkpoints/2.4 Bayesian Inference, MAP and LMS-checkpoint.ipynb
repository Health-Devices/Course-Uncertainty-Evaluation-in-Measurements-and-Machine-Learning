{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Bayesian Inference, MAP and LMS.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "+ Bayesian approach \n",
    "\n",
    "+ Different cases in Bayesian approach  \n",
    " \n",
    "+ Discrete,Continuous probability functions and their relationship with MAP and LMS estimated.      \n",
    "\n",
    "+ Point Estimation,Hypothesis Testing.\n",
    " \n",
    "+ Theory Behind MAP and LMS\n",
    "\n",
    "+ Use of Bayesian Approach in measurement\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  List of symbols used:\n",
    "\n",
    "$\\Theta$ - unknown random variable\n",
    "\n",
    "$\\theta$ - unknown parameter(constant)\n",
    "\n",
    "$X$      - known random variable\n",
    "\n",
    "$p$      - probability mass function\n",
    "\n",
    "$f$      - probability density function\n",
    "\n",
    "$\\hat{\\Theta}$ - estimator\n",
    "\n",
    "$\\hat{\\theta}$ - estimate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Approach\n",
    "\n",
    "  In general,bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. It is an important technique mainly in mathematical statistics and also in statistics. Bayesian updating is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a wide range of works and fields, including science, engineering, philosophy, medicine, sport, and law......[1] \n",
    " \n",
    "  In this approach,$\\Theta$ is the unknown quantity of interest.It is modeled as a finite collection of random variables or as a random variable.Generally $\\Theta$ here represent physical quantities like position,velocity of vehicle or set of unknown parameters of a probabilistic model.Unless its stated explicitly we consider $\\Theta$ as a single random variable\n",
    "\n",
    "Here our aim is to find the information about $\\Theta$ by observing a collection $X=(X_1,....X_n)$ of related random variables, called observations or measurements or observation vector.To do this we assume some things like we know i) joint distribution of $\\Theta$ and $X$ ii)Prior distribution $p_\\Theta$ for discrete and $f_\\Theta$ for continuous iii)Conditional distribution $p_{X \\mid \\Theta}$ for discrete and $f_{X \\mid \\Theta}$ for continuous\n",
    "\n",
    "here $\\Theta$ is unknown and it is treated as random variable. prior distribution $p_\\Theta$ for discrete and $f_\\Theta$ for continuous comes from symmetry, known range, earlier studies, subjective or arbitrary.\n",
    "\n",
    "After observing the value of x of X ,the answer for the problem is provided by the posterior distribution of the bayesian interface which is $p_{\\Theta \\mid X}(\\theta \\mid x)$ for discrete and $f_{\\Theta \\mid X}(\\theta \\mid x)$ for discrete of $\\Theta$.\n",
    "\n",
    "The posterior distribution is calculated by using the baye's rule.It binds complete information of $\\Theta$ ,given available information.This is the starting point for the further analysis like Point Estimates,Error Analysis etc.....[2]\n",
    "\n",
    "Steps in Bayesian Inference model\n",
    "step 1: It starts with the joint distribution of the parameters unknown $\\Theta$ and Observation X. or The prior distribution  $p_\\Theta$ or  $f_\\Theta$ and the conditional distribution $p_{X \\mid \\Theta}$ (PMF) or $f_{X \\mid \\Theta}$ (PDF)\n",
    "\n",
    "Step 2: As the value x of the observation is given by the Observation process the posterior distribution $p_{\\Theta \\mid X}(\\theta \\mid x)$ (PMF) or $f_{\\Theta \\mid X}(\\theta \\mid x)$ (PDF)is calculated by using Bayes' rule.\n",
    "\n",
    "Step3: The output from the posterior distribution can be used for further analysis, Estimates or associated probabilities or error variances.\n",
    "\n",
    "\n",
    "### Summary of Bayesian Inference\n",
    "Prior distribution $p_{\\Theta}$ or $_{\\Theta}$ is calculated for random variable $\\Theta$ which is unknown\n",
    "\n",
    "Using a model $p_{\\Theta \\mid X}$ or $f_{\\Theta \\mid X}$ w.r.t Observation Vector X.\n",
    "\n",
    "Once we observe the value of x of X , we calculate Posterior distribution of $\\Theta$ by using the Bayes' rule.\n",
    "\n",
    "As there are four versions of Bayes' we should use appropriate version to find $p_{\\Theta \\mid X}(. \\mid X = x)$ ( posterior distribution)\n",
    "\n",
    "The output of the Bayesian inference is Posterior distribution  $p_{\\Theta \\mid X}(. \\mid X = x)$ (PMF) or $f_{\\Theta \\mid X}(. \\mid X = x)$ (PDF)\n",
    "\n",
    "Summary of Bayesian Inference Model Below figure.......(Copied from [2]) \n",
    "\n",
    "\n",
    "![1](2.4/1.PNG \"Bayesian Inference Model\")\n",
    "\n",
    "  Above figure is  summary of Bayesian Inference model.Starting point is joint distribution of parameter $\\Theta$ and observation  $X$ or equivalently the prior and conditional PMF/PDF.Given the value $x$ of the observation $X$.The  posterior PMF/PDF is formed using Bayes rule.The posterior can be used to answer additional inference questions for example the calculation of estimates of $\\Theta$ and associated probabilities or error variances. \n",
    "\n",
    "\n",
    "\n",
    "### Four versions of Bayes Rule:\n",
    "\n",
    "There are four different versions of Bayes' rules as we are going to take two inputs $\\Theta$ $X$ for different combinations.\n",
    "\n",
    "\n",
    "i) $\\Theta$, $X$ \n",
    "are discrete:\n",
    "\n",
    "$$p_{\\Theta \\mid X}(\\theta \\mid x) = \\frac{p_{\\Theta}(\\theta)p_{X \\mid \\Theta}\n",
    "                        (x\\mid \\theta)}{\\sum_{\\theta^{'}} p_\\Theta(\\theta^{'}) P_{X\\mid \\Theta}(x \\mid \\theta^{'})} $$\n",
    "\n",
    "ii) $\\Theta$ is discrete and $X$ is continuous:\n",
    "                                   $$p_{\\Theta \\mid X}(\\theta \\mid x) = \\frac{p_{\\Theta}(\\theta)f_{X \\mid \\Theta}(x\\mid \\theta)}{\\sum_{\\theta^{'}}p_\\Theta(\\theta^{'}) f_{X\\mid \\Theta}(x \\mid \\theta^{'})} $$\n",
    "\n",
    "iii) $\\Theta$ is continuous and $X$ is discrete :\n",
    "                                  $$f_{\\Theta \\mid X}(\\theta \\mid x) = \\frac{f_{\\Theta}(\\theta)p_{X \\mid \\Theta}(x\\mid \\theta)}{\\int_{\\theta^{'}}f_\\Theta(\\theta^{'}) P_{X\\mid \\Theta}(x \\mid \\theta^{'})d\\theta^{'}} $$\n",
    "\n",
    "iv) $\\Theta$ , $X$ are continuous:\n",
    "               $$f_{\\Theta \\mid X}(\\theta \\mid x) = \\frac{f_{\\Theta}(\\theta)f_{X \\mid \\Theta}(x\\mid \\theta)}{\\int_{\\theta^{'}}f_\\Theta(\\theta^{'}) f_{X\\mid \\Theta}(x \\mid \\theta^{'})d\\theta^{'}} $$\n",
    "\n",
    "All four versions are syntactically similar.Generally here we are taking PDF for continuous random variable and changing it into PMF for discrete random variable.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Point Estimation,Hypothesis Testing, and The MAP rule:\n",
    "  \n",
    "  Let's first know about Posterior distribution,\n",
    "  It is the distribution which is prior and comes from the known range.It is what you believe(subjective)....[5]\n",
    "  \n",
    "  ### MAP Rule:\n",
    "  \n",
    "  The posterior distribution, $f_{X|Y}(x|y)$ or $P_{X|Y}(x|y)$, contains all the knowledge about the unknown quantity $X$. Therefore, we can use the posterior distribution to find point or interval estimates of $X$. One way to obtain a point estimate is to choose the value of x that maximizes the posterior PDF (or PMF). This is called the maximum a posteriori (MAP) estimation......[5]\n",
    "\n",
    "\n",
    "  Let's take an observation value x and select a value of $\\theta$ which is denoted as $\\hat{\\theta}$,that maximizes posterior distribution.....[2]   \n",
    "  \n",
    "$p_{\\Theta \\mid X}(\\theta\\mid x)$ [or $f_{\\Theta \\mid X}(\\theta\\mid x)$,if $\\Theta $ is continuous]:\n",
    "  \n",
    "($\\Theta$ discrete)\n",
    "\n",
    "$$\\hat{\\Theta} = arg\\underset{\\theta}{max} p_{\\Theta \\mid X}(\\theta \\mid x)$$\n",
    " \n",
    "($\\Theta$ continuous)\n",
    "$$\\hat{\\Theta} = arg\\underset{\\theta}{max} f_{\\Theta \\mid X}(\\theta \\mid x)$$   \n",
    "\n",
    "\n",
    "+ Equivalently, it selects $\\hat{\\theta}$ that maximizes over $\\theta$\n",
    "\n",
    "i)$\\quad$ If $\\Theta$ and X are discrete:\n",
    "\n",
    "$$p_{\\Theta}(\\theta)p_{ X \\mid \\Theta }( x \\mid \\theta )$$\n",
    "                    \n",
    "\n",
    "ii)$\\quad\\Theta$ is discrete and $X$ is continuous:\n",
    "                               \n",
    "$$p_{\\Theta}(\\theta)f_{ X \\mid \\Theta}( x \\mid \\theta )$$\n",
    "                                \n",
    "iii)$\\quad\\Theta$ is continuous and $X$ is discrete :\n",
    "\n",
    "$$f_{\\Theta}(\\theta)p_{ X \\mid \\Theta }( x \\mid \\theta )$$\n",
    "                    \n",
    "                                  \n",
    "iv)$\\quad \\Theta$ , $X$ are continuous:\n",
    "              \n",
    "$$f_{\\Theta}(\\theta)f_{ X \\mid \\Theta }( x \\mid \\theta )$$\n",
    "\n",
    "For any given value x and both conditional and unconditional probability of error, the MAP rule minimizes the probability of selecting incorrect hypothesis if $\\Theta$ takes finite number of values.....[2]\n",
    "\n",
    "below figure copied from.....[2]\n",
    "\n",
    "\n",
    "![2](2.4/2.PNG \"Posterior Distribution\")\n",
    "\n",
    "Above figure is illustration of MAP rule for inference of a continuous parameter(left figure) and discrete parameter(right figure).\n",
    "\n",
    "                    \n",
    "###### example:\n",
    "Let X be the number of heads observed  in $n$ independent tosses of a biased coin. We assume that the\n",
    "prior distribution of $\\theta$, the probability of heads, is uniform over [0, 1] . We will derive the MAP estimator $\\theta$.....example copied from [2].\n",
    "\n",
    "  $$f_{\\Theta \\mid X }(\\theta \\mid X=x)=\\frac{f_{\\Theta}(\\theta)p_{ X \\mid \\Theta }( X=x \\mid \\theta )}{p_X(X=x)}$$\n",
    "  \n",
    "  $$p_{ X \\mid \\Theta }( X=x \\mid \\theta )=\\prod_{i=1}^{n}p_{ X \\mid \\Theta }( x \\mid \\theta )=\\binom{n}{x}\\theta^x( 1-\\theta)^{n-x}$$\n",
    "  \n",
    "  $$\\int_0^1p_{ X \\mid \\Theta }( X=x \\mid \\theta )f_{\\Theta}(\\theta)d\\theta=\\frac{1}{(n+1)\\binom{n}{x}}$$\n",
    "\n",
    "posterior PDF\n",
    "  $$f_{\\Theta \\mid X }(\\theta \\mid X=x)=\\frac{p_{ X \\mid \\Theta }( X=x \\mid \\theta )f_{\\Theta}(\\theta)}{\\int_0^1p_{ X \\mid \\Theta }( X=x \\mid \\theta )f_{\\Theta}(\\theta)d\\theta}$$\n",
    "  \n",
    "  $$\\quad\\quad\\quad\\quad\\quad\\quad=(n+1)\\binom{n}{x}\\theta^x( 1-\\theta)^{n-x}$$ \n",
    "  $x$ number of heads observed\n",
    "  \n",
    "  \n",
    "  To find $\\Theta_{MAP}$ deriving posterior distribution with respect to $\\theta$ and equating it to 0.\n",
    "  \n",
    "  $$\\frac{d}{d\\theta}\\left( (n+1)\\binom{n}{x}\\theta^x( 1-\\theta)^{n-x} \\right)=0$$\n",
    "  \n",
    "  ###### MAP estimate\n",
    "  $$ \\hat{\\theta}_{MAP}=\\frac{x}{n}$$ \n",
    "  \n",
    "  ###### MAP estimator\n",
    "  $$\\hat{\\Theta}_{MAP}=\\frac{X}{n}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP estimate 0.3003003003\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18d8cdfd2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def posterior(n, x, t):\n",
    "    return (n + 1) * st.binom(n, t).pmf(x)\n",
    "\n",
    "n = 10 # number of samples\n",
    "x = 3 #number of heads obtained when biased coin is tossed\n",
    "theta = np.linspace(0., 1., 1000)\n",
    "d = posterior(n, x, theta)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(theta, d, '-k')\n",
    "ax.set_xlabel('theta parameter')\n",
    "ax.set_ylabel('Posterior distribution')\n",
    "ax.set_ylim(0, d.max() + 1)\n",
    "dist=d.max()\n",
    "MAP = theta[d.argmax()]\n",
    "print ('The MAP estimate',MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Estimation:\n",
    "If we select a single numerical value i.e,'point estimate'  it represents our best guess of the value $\\Theta$.The term 'estimate' is used to represent the numerical value of $\\hat{\\Theta}$ which we choose to report based on actual observation $x$.By applying some function '$g$' to $x$ the value of $\\hat{\\Theta}$ is determined.Resulting $\\hat{\\Theta} = g(x)$ .The value $\\hat{\\Theta} = g(X)$ is called Estimator.\n",
    "\n",
    "Here $\\hat{\\Theta}$ is random variable as the estimation outcome depends on random observation values.\n",
    "\n",
    "$\\textbf{Maximum a posteriori Probability  Estimator:}$ The MAP estimator sets the $\\hat{\\Theta}$ to a value that maximizes the posterior distribution over all possible values of $\\Theta$,if the value $x$ of $X$ is observed.\n",
    "\n",
    "$$p_{\\Theta  \\mid X}(\\theta^* \\mid x) = max_\\theta p_{\\Theta \\mid X}(\\theta \\mid x)$$\n",
    "$$f_{\\Theta  \\mid X}(\\theta^* \\mid x) = max_\\theta f_{\\Theta \\mid X}(\\theta \\mid x)$$\n",
    "\n",
    "$\\textbf{Conditional Estimator(Least Mean Square):}$ Conditional estimator sets the $\\hat{\\Theta}$ to $\\textbf{E}$ $[\\Theta \\mid X = x]$ if the value $x$ of $X$ is observed.....[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing:\n",
    "In this, we may use Bayes' rule to calculate the posterior probabilities $\\textbf{P}$ $(\\Theta = \\theta_i \\mid X = x)$ = $p_{\\Theta\\mid X} (\\theta_i \\mid x))$ for each i.Once the value of $x$ of $X$ is observed.We can also use MAP rule to select the largest posterior probability,As it maximizes the probability of correct decision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Least Mean Square Estimation:\n",
    "It is the conditional expectation error which results in least mean squared error.\n",
    "\n",
    "$\\textbf{Mean squared Error:}$\n",
    " It is, the difference between the estimator and what is estimated.The mean squared error (MSE) or mean squared deviation (MSD) of an estimator  measures the average of the squares of the errors or deviations—that . MSE is a risk function, corresponding to the expected value of the squared error loss or quadratic loss. The difference occurs because of randomness or because the estimator doesn't account for information that could produce a more accurate estimate.\n",
    " \n",
    " $\\textbf{Estimator :}$\n",
    " \n",
    "The MSE of an estimator  $\\hat {\\theta }$ with respect to an unknown parameter $ \\theta $ is defined as\n",
    "\n",
    "$MSE(\\hat{\\theta})= E_\\hat{\\theta}[(\\hat{\\theta}- \\theta)^2]$............[4]\n",
    "\n",
    "\n",
    "\n",
    "$\\textbf {LMS Estimation in the absence of observations:}$\n",
    "          \n",
    "Let's estimate $\\Theta$ with an constant $\\hat{\\theta}$ and observation $X$ is missing.The estimation error $\\hat{\\theta} - \\Theta$ is random but the mean squared error $\\textbf{E}$[($\\Theta-\\hat{\\theta})^2$] is a number that depends on $\\hat{\\theta}$  and can be minimized over $\\hat{\\theta}$ .So, setting $\\hat{\\theta}$  equal to $\\textbf{E}[\\Theta]$ is the best possible estimate.\n",
    "\n",
    "  $\\textbf{E}[Z]^2$ =  $\\textbf{var(Z)} $ + $\\textbf{(E}[Z])^2$ formula is used by first equality in the above.\n",
    "  and the second holds as $\\hat{\\theta}$ is subtracted from random variable $\\Theta$.The variance remains same and the mean is reduced by $\\hat{\\theta}$.So,we know that  $\\textbf {var ($\\Theta$) }$ does not depend on $\\hat{\\theta}$ and  $\\hat{\\theta}$ is to be chosen to minimize the term $\\textbf{E}$[($\\Theta-\\hat{\\theta})^2$] which leads to $\\hat{\\theta}$ = $\\textbf { E ($\\Theta$) }$.......[2]\n",
    "  \n",
    "below figure copied from....[2]\n",
    "\n",
    "\n",
    "![3](2.4/3.PNG \"MSE\")\n",
    "\n",
    "$\\textbf{Fig:}$The mean squared error  $\\textbf{E}$[($\\Theta-\\hat{\\theta})^2$],as a function of estimate $\\hat{\\theta}$,is a quadratic in $\\hat{\\theta}$, and is minimum value of the mean squared error is $\\textbf{var}$$(\\Theta).$\n",
    " \n",
    " $\\textbf {LMS Estimation of $\\Theta$ based on X  :}$\n",
    "  \n",
    "  If we use an observation  $X$ to estimate $\\Theta$ so that the mean square error is minimized.And we know the value $x$ of $X$ it will be same scenario as above except we have everything coditioned here on $X$ = $x$.So,we can conclude and assert that  $\\textbf{E}$[($\\Theta \\mid X = X)$],conditional expectation  minimizes the conditional mean squared error $\\textbf{E}$[($\\Theta - \\theta)^2 \\mid X = X)$] over all constants $\\hat{\\theta}$....[2].\n",
    "  \n",
    "The estimator $g(X)$ associated with unconditional mean squared estimation is defined as $\\textbf{E}$[($\\Theta - \\mid g(X))^2 $].\n",
    "    \n",
    " If we assume $\\textbf{E}$[($\\Theta \\mid X)$]as an estimator of $X$ the above mentioned analysis shows when $g(X)$ = $\\textbf{E}$[($\\Theta \\mid X)$],the mean squared error is minimized.For any given value of $x$ of $X$ and $g(X)$ is a number.\n",
    " \n",
    "  $\\textbf{E}$[($\\Theta - E[\\Theta \\mid X])^2]$ $\\leq$  $\\textbf{E}$[($\\Theta - g(X))^2 $], for all estimators $g(X).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\textbf{LMS Estimation with multiple observations or unknowns:}$\n",
    "\n",
    "In above discussion stated that $X$ was a single random variable.The entire argument and conditions apply even if $X$ is vector of random  variables $X = X_1,....X_n$.So,the mean square estimation error is minimized if we use $\\textbf{E}[\\Theta \\mid X_1...,X_n]$ as our estimator.\n",
    "\n",
    "$$\\textbf{E}[(\\Theta - E[\\Theta \\mid X_1...,X_n])^2]   \\leq   E[(\\Theta - g(X_1,....,X_n))^2],$$\n",
    "     \n",
    "For all estimators $g(X_1,....X_n).$\n",
    "\n",
    "For Estimating multiple parameters $\\Theta_1,....,\\Theta_m $,It is natural to consider \n",
    "$$\\textbf{E}[(\\Theta_1 - \\hat{\\Theta_1})^2]+.......+\\textbf{E}[(\\Theta_m - \\hat{\\Theta_m})^2].$$ and minimize it over all estimators  $\\Theta_1,....,\\Theta_m.$\n",
    "\n",
    "But  this is equivalent to finding i, an estimator $\\hat{\\Theta}$ that minimizes $\\textbf{E}[(\\Theta_1 - \\hat{\\Theta_1})^2]$ so, we are dealing with n decoupled estimation problems ,one for each unknown parameter\n",
    "$\\Theta_1$ resulting in $\\hat{\\Theta_i}$ = $\\textbf{ E}[\\Theta \\mid X_1...,X_n].$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Let X be the number of heads observed  in $n$ independent tosses of a biased coin. We assume that the\n",
    "prior distribution of $\\theta$, the probability of heads, is uniform over [0, 1] . We will derive the LMS estimator $\\theta$.....example copied from [2].\n",
    "\n",
    "\n",
    "since $\\theta$ is a probability value, our prior must respect θ∈(0,1) . We will use the (conjugate) Beta prior:θ∼Beta($\\alpha,\\beta$).\n",
    "\n",
    "($\\alpha,\\beta$) are the model’s hyperparameters. Then the prior is specified as:\n",
    "\n",
    "$$f_\\Theta(\\theta;\\alpha,\\beta)=\\frac{1}{B(\\alpha,\\beta)}\\theta^{\\alpha-1}( 1-\\theta)^{\\beta-1}$$\n",
    "\n",
    "Beta function is given by,\n",
    "\n",
    "$$B(\\alpha,\\beta) = \\int_0^1 {\\theta}^{\\alpha-1}(1-\\theta)^{\\beta-1}d\\theta=\\frac{(\\alpha-1)!(\\beta-1)!}{(\\alpha+\\beta-1)!}$$\n",
    "\n",
    "B($\\alpha,\\beta$) is the Beta function. Note that to have a fully specified prior, we need to also specify the hyperparameters.\n",
    "\n",
    "For $\\alpha=1$ and $\\beta=1$ the beta distribution will be uniform distribution.\n",
    "\n",
    "posterior:\n",
    "\n",
    "$$f_{\\Theta \\mid X}(\\theta \\mid X;\\hat{\\alpha},\\hat{\\beta})=\\frac{1}{B(\\hat{\\alpha},\\hat{\\beta})}\\theta^{\\hat{\\alpha}-1}( 1-\\theta)^{\\hat{\\beta}-1}$$\n",
    "$\\hat\\alpha= k+\\alpha= k+1$ and $\\hat\\beta=n-k+\\beta=n-k+1$\n",
    "\n",
    "mth moment of beta density function is given by,\n",
    "$$E[\\Theta^m]=\\frac{1}{B(\\alpha,\\beta)}\\int_0^1 {\\theta}^{m+\\alpha-1}(1-\\theta)^{\\beta-1}d\\theta$$\n",
    "$$=\\frac{B(\\alpha+m,\\beta)}{B(\\alpha,\\beta)}\\quad\\quad\\quad\\quad $$\n",
    "$$ \\quad\\quad\\quad\\quad\\quad=\\frac{\\alpha(\\alpha+1).....(\\alpha+m-1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)).....(\\alpha+\\beta+m-1)}$$\n",
    "\n",
    "Obtaining the conditional expectation estimate from above mean of the beta density formula:\n",
    "\n",
    "$$E[\\Theta \\mid X=k]=\\frac{\\alpha}{\\alpha+\\beta}=\\frac{k+1}{n+2}$$\n",
    "k=number of heads observed\n",
    "Mean of the beta density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least mean square estimate 0.23529411764705882\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f6dd2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline\n",
    "\n",
    "n = 100#number of trials\n",
    "theta = 0.3 #true value\n",
    "X = np.random.binomial(1, theta, n)\n",
    "A = np.linspace(0,1,100)#uniform dist\n",
    "a=1\n",
    "b=1\n",
    "B=st.beta(a,b).pdf(A)#uniform prior alpha=1 beta=1\n",
    "\n",
    "\n",
    "# The hyperparameters of the posterior\n",
    "a_hat = a + X.sum()\n",
    "b_hat = b + n - X.sum()\n",
    "\n",
    "\n",
    "mean, var, skew, kurt = beta.stats(a_hat, b_hat, moments='mvsk')\n",
    "print('least mean square estimate',mean)\n",
    "\n",
    "plt.title('Posterior Distribution')\n",
    "plt.plot(A, st.beta(a_hat, b_hat).pdf(A), 'r');\n",
    "\n",
    "# Plot the prior\n",
    "plt.plot(A, st.beta(a, b).pdf(A), 'g');\n",
    "\n",
    "plt.ylim(0,12)\n",
    "plt.legend(['Posterior (Analytic)', 'Prior']);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of Bayesian Approach in measurements: \n",
    "\n",
    "$\\textbf{Repeated Measurements:}.$\n",
    "lets say a quantity Q is measured independently n times, the results are the values q = ( q1 . . . qn )T. No prior \n",
    "knowledge about Q is available. It is desired to obtain the corresponding best estimate and standard certainty.\n",
    " We can use Bayesian alternative. The first applies to the case in which the values q are assumed to be sampled \n",
    "from a normal probability model and  rectangular probability model. \n",
    "\n",
    "$\\textbf{Normal Probability Model :}$\n",
    " Whenever a set of observations $\\textbf{q}$ about Q is given, one should try to dwell on the physical reasons that lead to the appearance of different values. If the experimental evidence leads us to believe that the deviations of the $q_i$s from the (true) value of the quantity are caused by several random effects and that these deviations are independent of one another, it is reasonable to think of the data as being drawn independently from an infinite population of values whose frequency distribution is normal, centred at the unknown value of the quantity Q and having an unknown variance V .\n",
    "From the Bayesian point of view, Q and V are considered as being two measurands, only the first of which is identified with a physical quantity. The relationship between Q and $V$ does not arise from the measurement model, but from the probability model. The quantity $V$ is normally not of interest in itself, but its existence conditions what we can infer about Q. In Bayesian theory, a quantity such as V is called a nuisance parameter.\n",
    "Conditional on given values q of Q and v of V , the pdf for any given datum qi follows from the probability model and is\n",
    "\n",
    "$$f(q_i \\mid q, v) \\propto \\frac{1}{v^\\frac{1}{2}}exp\\left[-\\frac{1}{2}\\frac{{ (q_i - q)}^2}{ v}\\right]$$ \n",
    "\n",
    "In the context of BT, this density is interpreted as being proportional to the likelihood function $l(q, v|qi )$. Since the observations are assumed to be independent, the global likelihood $l(q,v|\\textbf{q})$ is obtained by multiplying the individual likelihoods. Moreover, since Q and V are also independent, and they act as location and scale parameters, respectively, their joint prior separates into the product of a constant (Bayes’ prior) for the former multiplied by v−1 (Jeffreys’ prior) for the latter. The joint posterior becomes..........[3].\n",
    "\n",
    "\n",
    "$$f(q ,v  \\mid \\textbf{q} ) \\propto \\frac{1}{v^\\frac{n}{2+1}}exp\\left[-\\frac{1}{2v}\\sum_{i=1}^{n}{{ (q_i - q)}^2}\\right]$$ \n",
    "\n",
    "By rearranging \n",
    "\n",
    "$$\\sum_{i=1}^{n}{{ (q_i - q)}^2}= (n-1)s^2 + n(q - \\bar q)^2 $$\n",
    "\n",
    "where $$\\bar q = \\frac{1}{n}\\sum_{i=1}^{n}{{q_i}}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{{ (q_i - \\bar q)}^2}$$\n",
    "\n",
    "$$f(q ,v  \\mid\\textbf{q}) \\propto \\frac{1}{v^\\frac{n}{2+1}}exp\\left[-\\frac{1}{2}\n",
    "\\frac{{(n-1)}{s^2}+n{(q -\\bar q)^2}}{v}\\right]$$\n",
    "\n",
    "Note that in this analysis q and s2 are just shorthand notation; these parameters should not be interpreted here as estimates of the mean and variance of the parent distribution.\n",
    "\n",
    "Inference about Q\n",
    "\n",
    "$$ u_q^2 = \\frac{(rs)^2}{n}.$$ \n",
    "\n",
    "where $r^2$ is variance of PDF.\n",
    "\n",
    "Inference about V\n",
    "\n",
    "\n",
    "\n",
    "$$ u_v^2 = \\frac{2(rs)^4}{n- 5}.$$\n",
    "\n",
    "$\\textbf{Example:}.$\n",
    "\n",
    " A quantity Q is measured repeatedly 10 times. The resulting numeric values are:\n",
    "7.489 7.503 7.433 7.549 7.526 7.396 7.543 7.509 7.504 7.383\n",
    "and the unit is mm. These values give $q_e = \\bar q $ = 7.484 mm\n",
    "$s^2$ = 0.003 492 mm2 and $r^2$ = 1.2857. The TA procedure gives $u_q$ = 0.019 mm. The Bayesian method produces instead $u_q$ = 0.021 mm. The latter also gives $v_e$ = 0.004 489 mm2 and $u_v$= 0.002 839 mm2.The below  figures represent the pdfs ......[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![12](2.4/12.PNG \"Pdf\")\n",
    "\n",
    "The pdf for Q with normal probability model. The parameters are n = 10 and s2 = 0.003 492."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![13](2.4/13.PNG \"Pdf\")\n",
    "The pdf for V with normal probability model. The parameters are n = 10 and\n",
    "s2 = 0.003 492."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Rectangular Probability Model :}$\n",
    "\n",
    "Suppose now that the normal probability model used in the previous subsection is not realistic. For example, assume that the value of Q cannot be taken as fixed, because it is known that it varies randomly between two limits that are not perfectly known. If the time interval between measurements is larger than the characteristic fluctuation time, the values q may be considered to be sampled from a rectangular parent distribution centred at Q and having a half-width W, the latter being a nuisance (scale) parameter.\n",
    "    Conditional on given values q of Q and w of W , the pdf for each datum qi , considered as a variable, is rectangular in the interval $(q −w, q +w).$ Accordingly, its likelihood is proportional to 1/w over this interval and is zero otherwise. The multiplication of all the individual likelihoods yields a global likelihood proportional to 1/wn valid for $q−w<q_1$,...,$q_n <q+w$. This last condition is equivalent to $q−w<q_a ≤ q_b <q+w$, where $q_a = min{q}$ and $q_b = max{q}$.\n",
    "    \n",
    "With a constant prior for Q and a 1/w prior for W, the joint posterior\n",
    "becomes\n",
    "\n",
    "\n",
    "$$f(q, w \\mid \\textbf{q}) \\propto \\frac{1}{w^{n+1}}$$ \n",
    "\n",
    "\n",
    "for  $q - w $< $q_a$ and $q_b$ < $q+w$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Inference about Q\n",
    "\n",
    "$$ u_q^2 =  \\frac{\\delta ^2}{2(n - 2)(n - 3)}$$  where $\\delta = q_b - q_a$\n",
    "\n",
    "\n",
    "Inference about w\n",
    "\n",
    "\n",
    "$$ u_w^2 =  \\frac{2n}{(n - 2)^2(n - 3)}\\left(\\frac{\\delta}{2}\\right)^2$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Example:}.$ we have $q_a$ = 7.383 mm, $q_b$ =7.549mm and δ=0.166mm,from which $q_e =\\tilde{q}$= 7.466 mm, $u_q$ = 0.016 mm, $w_e$ = 0.104 mm and $u_w$ = 0.018 mm. Figures 6.8 and 6.9 depict the pdfs (6.16) and (6.17), respectively, that correspond to the values in this example. Because of its shape, the former may be termed the ‘cusp’ pdf..............[3]\n",
    "Below figures copied from.......[3].\n",
    "\n",
    "\n",
    "![14](2.4/14.PNG \"‘cusp’ pdf\")\n",
    "\n",
    "The cusp pdf for Q with rectangular probability model. The parameters are\n",
    "$q_a$ = 7.383, $q_b$ = 7.549 and n = 10.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![15](2.4/15.PNG \"pdf\")\n",
    "\n",
    "The pdf for W with parameters n = 10 and $\\delta$ = 0.166."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Bayesian inference https://en.wikipedia.org/wiki/Bayesian_inference\n",
    "\n",
    "[2] Dimitri P. Bertsekas and John N. Tsitsiklis INTRODUCTION TO PROBABILITY SECOND EDITION\n",
    "\n",
    "[3] Iganacio Lira EVALUATING THE MEASUREMENT UNCERTAINITY\n",
    "\n",
    "[4] Mean Squared Error https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "[5] Bolic, M. (2018). Principles of Data and Error Analysis in Engineering Measurements.\n",
    "\n",
    "[6] https://github.com/hyzhak/mle/blob/master/machine-learning-10-601-hm2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
